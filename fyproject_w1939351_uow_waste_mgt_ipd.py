# -*- coding: utf-8 -*-
"""FYProject_W1939351_UoW_Waste_Mgt_IPD.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ofks5GmsrFtU5pm1fmY6EuabTjSrwNd9

The **UoW Waste Data** folder contains eight Excel files, one for each academic session : 'Waste Data 2017_18', 'Waste Data 2018_19'. Waste Data 2019_20' and so on , up to 'Waste Data 2024_25' . Upon exploring the data, I observed that the files from 'Waste Data 2017_18' to 'Waste Data 2020_21' appear to be in the same format, the 'Waste Data 2021_22' file is on another format while 'Waste Data 2022_23 to Waste Data 2024_25' is also on a different format.
For easier insights and visualisation , our target variables (headings) for the *first format* would be "Address Name" (which contains all the locations/ campuses), "Recy_NonRecy" ( which contains the treatment types e.g Recycled, Incinerated, AD, Re-use, Reuse and Other), "Year", "Month" and "Kg".
The targeted variables for the second format are all the columns in the first format with the addition of "WasteType" .
While for the third format, our *tageted variables* will be "WasteType", Contractor, "Recy_NonRecy","Year", "Month", "Kg", "Total" and "Carbon Footprint".


**Waste Data Cleaning Step by Step for the first format** This code is used to clean the waste data from 2017_18 to 2020_21.
The first step is to import and install all the neccessary libraries that will help to read, transform and visualise the dataset. Then, upload all the monthly dataset into Colab.
The waste data for 2018_2019, 2019_20, and 2020_21 is slightly inconsistent with the first year and, therefore, required some manual preprocessing to fit into the first format. The adjusted datasets are used for these three years.

**Auto load the database**
"""



# Instal and Import neccessary libraries
!pip install openpyxl
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import sqlite3
import shutil
import os

"""**Dataset 2017-18**

**Waste Data Cleaning Step by Step for the first format**
"""

#Start the Waste Data 2017-18 cleaning
#Read the sheet without headers because we are going to form our own headers based on our targeted variables
Wdata17_18 = pd.read_excel("/content/Waste Data 2017-18_Adj.xlsx", header=None)

#sample of the uploaded dataset
Wdata17_18.head()

# delete row 26 downward (As showing from the Excel sheet, row 26 dowmward are summary/ duplicate of the data above it therefore needed to be deleted).
Wdata17_18 = Wdata17_18.drop(Wdata17_18.index[26:])

#print last 5 rows after summary/ duplicate of the data were deleted
Wdata17_18.tail()

# forming new headers based on our targeted variables

# These are the rows where our new columns will come from (0-based index):
year_row = 2    # Excel row 3
month_row = 3   # Excel row 4
address_name_row = 4  # Excel row 5

# 3. Find where each monthly block starts (cells in address_name_row that say "Address Name")
block_starts = [i for i, v in enumerate(Wdata17_18.iloc[address_name_row]) if str(v).strip().lower() == 'address name']

tidy = []
for start in block_starts:
    # recy_nonrecy labels are the next columns after the 'Address Name' column in this block
    recy_nonrecy = []
    for offset in range(1,6):
        c = start + offset
        if c >= Wdata17_18.shape[1]:
            break
        lab = str(Wdata17_18.iat[address_name_row, c]).strip()
        if lab and lab.lower() != 'nan':
            recy_nonrecy.append(lab)

    year = str(Wdata17_18.iat[year_row, start]).strip()
    month = str(Wdata17_18.iat[month_row, start]).strip()

    # rows below address_name_row are the address_name row ( e.g All, Boat House, Cavendish Sports Groud, ...)
    for r in range(address_name_row+1, Wdata17_18.shape[0]):
        address_name = Wdata17_18.iat[r, start]
        if pd.isna(address_name) or str(address_name).strip() == '':
            continue
        for j, recy_nonrecy_label in enumerate(recy_nonrecy):
            c = start + 1 + j
            if c >= Wdata17_18.shape[1]:
                continue
            kg = Wdata17_18.iat[r, c]
            if pd.isna(kg) or str(kg).strip() == '':
                continue
            tidy.append([str(address_name).strip(),
                         str(recy_nonrecy_label).strip(),
                         year,
                         month,
                         kg])

# 4. Make it a DataFrame and clean a bit
tidy_Wdata17_18 = pd.DataFrame(tidy, columns=['Address Name','Recy_NonRecy','Year','Month','Kg'])

month_mapping = { # this is neccessary because of inconsistence in the month's names
    'Jan': 'January',
    'Feb': 'February',
    'Mar': 'March',
    'Apr': 'April',
    'May': 'May',
    'Jun': 'June',
    'Jul': 'July',
    'Aug': 'August',
    'Sept': 'September',
    'Oct': 'October',
    'Nov': 'November',
    'Dec': 'December'
}

# quick clean-ups
tidy_Wdata17_18['Month'] = tidy_Wdata17_18['Month'].replace(month_mapping)
tidy_Wdata17_18['Year'] = tidy_Wdata17_18['Year'].str.extract(r'(\d{4})')  # keep only the 4-digit year
#change Kg to numeric
tidy_Wdata17_18['Kg'] = pd.to_numeric(tidy_Wdata17_18['Kg'], errors='coerce')

#check sample of the new dataset if is in-line with our target (variables)
tidy_Wdata17_18.head(10)

# print unique in Recy_NonRecy column
tidy_Wdata17_18['Recy_NonRecy'].unique()

#print sample
tidy_Wdata17_18.tail(10)

# Save tidy "tidy_Wdata17_18" to CSV
tidy_Wdata17_18.to_csv("Waste_2017_2018_Clean.csv", index=False)
print("Saved tidy CSV")

#confirm the total Kg column
tidy_Wdata17_18['Kg'].sum()

# calculate year_average for tidy_Wdata17_18['Kg'].sum()
year_average= (tidy_Wdata17_18['Kg'].sum())/12
print(f"The average for the year is {year_average}")

# print total Kg for each Month from August to July
for month in tidy_Wdata17_18['Month'].unique():
    total_kg = tidy_Wdata17_18[tidy_Wdata17_18['Month'] == month]['Kg'].sum()
    print(f"Total Kg for {month}: {total_kg}")

# check basic information of our clean dataset
tidy_Wdata17_18.info()

#check for missing value in the clean dataset
tidy_Wdata17_18.isnull().sum()

# bar chart for Month and Kg
tidy_Wdata17_18.groupby('Month')['Kg'].sum().plot(kind='bar')
plt.xlabel('Month')
plt.ylabel('Quantities in Kg')

#plot tidy_Wdata17_18 bar chart of Kg and Recy_NonRecy with label x-axis= "Tratment Method", y-axis = " Quantities in Kg" and Title = " Waste Treatment Methods and Quantities 2017-2018"
tidy_Wdata17_18.groupby('Recy_NonRecy')['Kg'].sum().plot(kind='bar')
plt.xlabel('Treatment Method')
plt.ylabel('Quantities in Kg')
plt.title('Waste Treatment Methods and Quantities 2017-2018')
plt.show()

#recycled for August
tidy_Wdata17_18[(tidy_Wdata17_18['Recy_NonRecy'] == 'Recycled') & (tidy_Wdata17_18['Month'] == 'August')]['Kg'].sum()

#Total recycled for August plus AD
tidy_Wdata17_18[
    (tidy_Wdata17_18['Recy_NonRecy'].isin(['Recycled', 'AD'])) &
    (tidy_Wdata17_18['Month'] == 'August')
]['Kg'].sum()

#%  recycled + AD for August
recycled_ad_aug = tidy_Wdata17_18.loc[
    tidy_Wdata17_18['Recy_NonRecy'].isin(['Recycled', 'AD']) &
    (tidy_Wdata17_18['Month'] == 'August'),'Kg'].sum()

total_aug = tidy_Wdata17_18.loc[
    tidy_Wdata17_18['Month'] == 'August', 'Kg'].sum()

percentage = (recycled_ad_aug / total_aug) * 100
print(f"Percentage of Recycled and AD in August: {percentage:.2f}%")

# %recycle for the whole period


# total kg for the whole period
total_kg = tidy_Wdata17_18['Kg'].sum()

# kg that is recycled or AD
recycled_kg = tidy_Wdata17_18[
    tidy_Wdata17_18['Recy_NonRecy'].isin(['Recycled', 'AD'])
]['Kg'].sum()

# percentage recycled
percentage = (recycled_kg / total_kg) * 100

print(f"Percentage of Recycled: {percentage:.2f}%")
print(recycled_kg)



# Check total for each month, recycled and percentage recycled
result = (
    tidy_Wdata17_18
    .groupby('Month')
    .apply(lambda x: pd.Series({
        'Total_Kg': x['Kg'].sum(),
        'Recycled_AD_Kg': x.loc[
            x['Recy_NonRecy'].isin(['Recycled', 'AD']), 'Kg'
        ].sum()
    }))
)

result['Recycled_AD_Percentage'] = (
    result['Recycled_AD_Kg'] / result['Total_Kg']
) * 100

print(result)

tidy_Wdata17_18.groupby('Recy_NonRecy')['Kg'].sum().plot(kind='pie', autopct='%1.1f%%')

# bar chart showing contribution of each location to the total waste generated for the period
#plot tidy_Wdata17_18 bar chart of Address Name and Kg and with label x-axis= "Location", y-axis = " Quantities in Kg" and Title =" Location of Waste Collected at UoW in 2017-2018 (Kg)"
tidy_Wdata17_18.groupby('Address Name')['Kg'].sum().plot(kind='bar')
plt.xlabel('Location')
plt.ylabel('Quantities in Kg')
plt.title('Location of Waste Collected at UoW in 2017-2018 (Kg)')
plt.show()



"""**2018_2019 Dataset**"""

#  Read the sheet without headers
Wdata18_19 = pd.read_excel("/content/Waste Data 2018-19_Adj.xlsx", header=None)

#check the sample
Wdata18_19.head()

# delete row 26 downward (As showing from the Excel sheet, row 26 dowmward are summary/ duplicate of the data above it therefore needed to be deleted).
Wdata18_19 = Wdata18_19.drop(Wdata18_19.index[26:])

#print sample tail
Wdata18_19.tail()

# forming new headers based on our targeted variables
# These are the rows we care about (0-based index):
year_row = 2    # Excel row 3
month_row = 3   # Excel row 4
address_name_row = 4  # Excel row 5

# 3. Find where each monthly block starts (cells in address_name_row that say "Address Name")
block_starts = [i for i, v in enumerate(Wdata18_19.iloc[address_name_row]) if str(v).strip().lower() == 'address name']

tidy = []
for start in block_starts:
    # recy_nonrecy labels are the next columns after the 'Address Name' column in this block
    recy_nonrecy = []
    for offset in range(1,6):
        c = start + offset
        if c >= Wdata18_19.shape[1]:
            break
        lab = str(Wdata18_19.iat[address_name_row, c]).strip()
        if lab and lab.lower() != 'nan':
            recy_nonrecy.append(lab)

    year = str(Wdata18_19.iat[year_row, start]).strip()
    month = str(Wdata18_19.iat[month_row, start]).strip()

    # rows below address_name_row are the address_name row  ( e.g All, Boat House, Cavendish Sports Groud, ...)
    for r in range(address_name_row+1, Wdata18_19.shape[0]):
        address_name = Wdata18_19.iat[r, start]
        if pd.isna(address_name) or str(address_name).strip() == '':
            continue
        for j, recy_nonrecy_label in enumerate(recy_nonrecy):
            c = start + 1 + j
            if c >= Wdata18_19.shape[1]:
                continue
            kg = Wdata18_19.iat[r, c]
            if pd.isna(kg) or str(kg).strip() == '':
                continue
            tidy.append([str(address_name).strip(),
                         str(recy_nonrecy_label).strip(),
                         year,
                         month,
                         kg])


# 4. Make it a DataFrame and clean a bit
tidy_Wdata18_19 = pd.DataFrame(tidy, columns=['Address Name','Recy_NonRecy','Year','Month','Kg'])

month_mapping = {
    'Jan': 'January',
    'Janurary': 'January',
    'Feburary': 'February',
    'Feb': 'February',
    'Mar': 'March',
    'Apr': 'April',
    'May': 'May',
    'Jun': 'June',
    'Jul': 'July',
    'Aug': 'August',
    'Sept': 'September',
    'Oct': 'October',
    'Nov': 'November',
    'Dec': 'December'
}

# quick clean-ups
tidy_Wdata18_19['Month'] = tidy_Wdata18_19['Month'].replace(month_mapping)
tidy_Wdata18_19['Year'] = tidy_Wdata18_19['Year'].str.extract(r'(\d{4})')  # keep only the 4-digit year
#change Kg to numeric
tidy_Wdata18_19['Kg'] = pd.to_numeric(tidy_Wdata18_19['Kg'], errors='coerce')

#sample
tidy_Wdata18_19.head(10)

#tail
tidy_Wdata18_19.tail()

#check for missing value
tidy_Wdata18_19.isnull().sum()

#check info
tidy_Wdata18_19.info()

#unique Recy_NonRecy
tidy_Wdata18_19['Recy_NonRecy'].unique()

# Save tidy to CSV
tidy_Wdata18_19.to_csv("Waste_2018_2019_Clean.csv", index=False)
print("Saved tidy CSV")

#total Kg column
tidy_Wdata18_19['Kg'].sum()

# print total Kg for each Month from August to July
for month in tidy_Wdata18_19['Month'].unique():
    total_kg = tidy_Wdata18_19[tidy_Wdata18_19['Month'] == month]['Kg'].sum()
    print(f"Total Kg for {month}: {total_kg}")

# Check total for each month, recycled and percentage recycled
# total kg per month (all waste types) to recycled
result = (
    tidy_Wdata18_19
    .groupby('Month')
    .apply(lambda x: pd.Series({
        'Total_Kg': x['Kg'].sum(),
        'Recycled_AD_Kg': x.loc[
            x['Recy_NonRecy'].isin(['Recycled', 'AD', 'Re-use']), 'Kg'
        ].sum()
    }))
)

result['Recycled_AD_Percentage'] = (
    result['Recycled_AD_Kg'] / result['Total_Kg']
) * 100

print(result)



# %recycled for the whole period


# total kg for the whole period
total_kg = tidy_Wdata18_19['Kg'].sum()

# kg that is recycled or AD
recycled_kg = tidy_Wdata18_19[
    tidy_Wdata18_19['Recy_NonRecy'].isin(['Recycled', 'AD' , 'Re-use'])
]['Kg'].sum()

# percentage recycled
percentage = (recycled_kg / total_kg) * 100

print(f"Percentage of Recycled: {percentage:.2f}%")
print(recycled_kg)



"""**2019/ 2020 Dataset**"""

#  Read the sheet without headers
Wdata19_20 = pd.read_excel("/content/Waste Data 2019-20_Adj.xlsx", header=None)

#check sample
Wdata19_20.head()

#delete row 26 downward
Wdata19_20 = Wdata19_20.drop(Wdata19_20.index[26:])

#check sample for confirmation (tail)
Wdata19_20.tail()

# forming new headers based on our targeted variables
# These are the rows we care about (0-based index):
year_row = 2    # Excel row 3
month_row = 3   # Excel row 4
address_name_row = 4  # Excel row 5

# 3. Find where each monthly block starts (cells in address_name_row that say "Address Name")
block_starts = [i for i, v in enumerate(Wdata19_20.iloc[address_name_row]) if str(v).strip().lower() == 'address name']

tidy = []
for start in block_starts:
    # recy_nonrecy labels are the next columns after the 'Address Name' column in this block
    recy_nonrecy = []
    for offset in range(1,6):
        c = start + offset
        if c >= Wdata19_20.shape[1]:
            break
        lab = str(Wdata19_20.iat[address_name_row, c]).strip()
        if lab and lab.lower() != 'nan':
            recy_nonrecy.append(lab)

    year = str(Wdata19_20.iat[year_row, start]).strip()
    month = str(Wdata19_20.iat[month_row, start]).strip()

    # rows below address_name_row are the address_name row (All, Boat House, Cavendish Sports Groud, ...)
    for r in range(address_name_row+1, Wdata19_20.shape[0]):
        address_name = Wdata19_20.iat[r, start]
        if pd.isna(address_name) or str(address_name).strip() == '':
            continue
        for j, recy_nonrecy_label in enumerate(recy_nonrecy):
            c = start + 1 + j
            if c >= Wdata19_20.shape[1]:
                continue
            kg = Wdata19_20.iat[r, c]
            if pd.isna(kg) or str(kg).strip() == '':
                continue
            tidy.append([str(address_name).strip(),
                         str(recy_nonrecy_label).strip(),
                         year,
                         month,
                         kg])

# 4. Make it a DataFrame and clean a bit
tidy_Wdata19_20 = pd.DataFrame(tidy, columns=['Address Name','Recy_NonRecy','Year','Month','Kg'])

month_mapping = {
    'Jan': 'January',
    'Feb': 'February',
    'Mar': 'March',
    'Apr': 'April',
    'May': 'May',
    'Jun': 'June',
    'Jul': 'July',
    'Aug': 'August',
    'Sept': 'September',
    'Oct': 'October',
    'Nov': 'November',
    'Dec': 'December'
}

# quick clean-ups
tidy_Wdata19_20['Month'] = tidy_Wdata19_20['Month'].replace(month_mapping)
tidy_Wdata19_20['Year'] = tidy_Wdata19_20['Year'].str.extract(r'(\d{4})')  # keep only the 4-digit year
#change Kg to numeric
tidy_Wdata19_20['Kg'] = pd.to_numeric(tidy_Wdata19_20['Kg'], errors='coerce')

# check sample
tidy_Wdata19_20.head()

#tail
tidy_Wdata19_20.tail()

#info
tidy_Wdata19_20.info()

#missing value
tidy_Wdata19_20.isnull().sum()

#unique Recy_NonRecy
tidy_Wdata19_20['Recy_NonRecy'].unique()

#total waste (Kg) column
tidy_Wdata19_20['Kg'].sum()

# print total Kg for each Month from August to July 19_20
for month in tidy_Wdata19_20['Month'].unique():
    total_kg = tidy_Wdata19_20[tidy_Wdata19_20['Month'] == month]['Kg'].sum()
    print(f"Total Kg for {month}: {total_kg}")

# Total recycled per month
result = (
    tidy_Wdata19_20
    .groupby('Month')
    .apply(lambda x: pd.Series({
        'Total_Kg': x['Kg'].sum(),
        'Recycled_AD_Kg': x.loc[
            x['Recy_NonRecy'].isin(['Recycled', 'AD', 'Re-use']), 'Kg'
        ].sum()
    }))
)

result['Recycled_AD_Percentage'] = (
    result['Recycled_AD_Kg'] / result['Total_Kg']
) * 100

print(result)



# %recycle for the whole period


# total kg for the whole period
total_kg = tidy_Wdata19_20['Kg'].sum()

# kg that is recycled or AD
recycled_kg = tidy_Wdata19_20[
    tidy_Wdata19_20['Recy_NonRecy'].isin(['Recycled', 'AD' , 'Re-use'])
]['Kg'].sum()

# percentage recycled
percentage = (recycled_kg / total_kg) * 100

print("Total waste generated for 2019_20 session : " , total_kg)
print("Total Recycled : ", recycled_kg)
print(f"Percentage of Recycled: {percentage:.2f}%")

#boxplot for Recy_NonRecy and kg 19_20
tidy_Wdata19_20.boxplot(column=['Kg'], by='Recy_NonRecy')

#pie chat for Kg and Recy_NonRecy
tidy_Wdata19_20.groupby('Recy_NonRecy')['Kg'].sum().plot(kind='pie', autopct='%1.1f%%')

#bar chart for Recy_NonRecy and Kg
tidy_Wdata19_20.groupby('Recy_NonRecy')['Kg'].sum().plot(kind='bar')

#bar chart for Recy_NonRecy and Kg and Month
tidy_Wdata19_20.groupby(['Recy_NonRecy', 'Month'])['Kg'] \
    .sum() \
    .unstack() \
    .plot(kind='bar', figsize=(10,6))

plt.ylabel('Kg')
plt.title('Monthly Recycling vs Non-Recycling (2019–2020)')
plt.show()

# Save tidy CSV
tidy_Wdata19_20.to_csv("Waste_2019_2020_Clean.csv", index=False)



"""**2020/2021 Dataset**"""

#  Read the sheet without headers
Wdata20_21 = pd.read_excel("/content/Waste Data 2020-21_Adj.xlsx", header=None)

#sample
Wdata20_21.head()

#delete 26 rows downward
Wdata20_21 = Wdata20_21.drop(Wdata20_21.index[26:])

#tail
Wdata20_21.tail()

# forming new headers based on our targeted variables
# These are the rows we care about (0-based index):
year_row = 2    # Excel row 3
month_row = 3   # Excel row 4
address_name_row = 4  # Excel row 5

# 3. Find where each monthly block starts (cells in address_name_row that say "Address Name")
block_starts = [i for i, v in enumerate(Wdata20_21.iloc[address_name_row]) if str(v).strip().lower() == 'address name']

tidy = []
for start in block_starts:
    # recy_nonrecy labels are the next columns after the 'Address Name' column in this block
    recy_nonrecy = []
    for offset in range(1,7):
        c = start + offset
        if c >= Wdata20_21.shape[1]:
            break
        lab = str(Wdata20_21.iat[address_name_row, c]).strip()
        if lab and lab.lower() != 'nan':
            recy_nonrecy.append(lab)

    year = str(Wdata20_21.iat[year_row, start]).strip()
    month = str(Wdata20_21.iat[month_row, start]).strip()

    # rows below address_name_row are the address_name row (All, Boat House, Cavendish Sports Groud, ...)
    for r in range(address_name_row+1, Wdata20_21.shape[0]):
        address_name = Wdata20_21.iat[r, start]
        if pd.isna(address_name) or str(address_name).strip() == '':
            continue
        for j, recy_nonrecy_label in enumerate(recy_nonrecy):
            c = start + 1 + j
            if c >= Wdata20_21.shape[1]:
                continue
            kg = Wdata20_21.iat[r, c]
            if pd.isna(kg) or str(kg).strip() == '':
                continue
            tidy.append([str(address_name).strip(),
                         str(recy_nonrecy_label).strip(),
                         year,
                         month,
                         kg])

# 4. Make it a DataFrame and clean a bit
tidy_Wdata20_21 = pd.DataFrame(tidy, columns=['Address Name','Recy_NonRecy','Year','Month','Kg'])

month_mapping = {
    'Jan': 'January',
    'Janurary': 'January',
    'Feburary': 'February',
    'Feb': 'February',
    'Mar': 'March',
    'Apr': 'April',
    'May': 'May',
    'Jun': 'June',
    'Jul': 'July',
    'Aug': 'August',
    'Sept': 'September',
    'Oct': 'October',
    'Nov': 'November',
    'Dec': 'December'
}

# quick clean-ups
tidy_Wdata20_21['Month'] = tidy_Wdata20_21['Month'].replace(month_mapping)
tidy_Wdata20_21['Year'] = tidy_Wdata20_21['Year'].str.extract(r'(\d{4})')  # keep only the 4-digit year
#change Kg to numeric
tidy_Wdata20_21['Kg'] = pd.to_numeric(tidy_Wdata20_21['Kg'], errors='coerce')

#sample
tidy_Wdata20_21.head()

#tail
tidy_Wdata20_21.tail()

#info
tidy_Wdata20_21.info()

#unique in Address Name column ( list of campuses where the wasted came from)
tidy_Wdata20_21['Address Name'].unique()

#missing value
tidy_Wdata20_21.isnull().sum()

# print total Kg for each Month from August to July
for month in tidy_Wdata20_21['Month'].unique():
    total_kg = tidy_Wdata20_21[tidy_Wdata20_21['Month'] == month]['Kg'].sum()
    print(f"Total Kg for {month}: {total_kg}")

#total kg column ( total waste generated 2020_21)
tidy_Wdata20_21['Kg'].sum()

#boxplot for Recy_NonRecy and kg
tidy_Wdata20_21.boxplot(column=['Kg'], by='Recy_NonRecy')

#pie chat for Kg and Recy_NonRecy
tidy_Wdata20_21.groupby('Recy_NonRecy')['Kg'].sum().plot(kind='pie', autopct='%1.1f%%')

#bar chart for Recy_NonRecy and Kg
tidy_Wdata20_21.groupby('Recy_NonRecy')['Kg'].sum().plot(kind='bar')

#bar chart showing Treatment methods in Kg and Month
tidy_Wdata20_21.groupby(['Recy_NonRecy', 'Month'])['Kg'] \
    .sum() \
    .unstack() \
    .plot(kind='bar', figsize=(10,6))

plt.ylabel('Kg')
plt.title('Treatment methods in Months (2020–2021)')
plt.show()

# Save tidy CSV
tidy_Wdata20_21.to_csv("Waste_2020_2021_Clean.csv", index=False)



"""2021/2022 Dataset

Below is the **Waste Data Cleaning Step by Step for the second format** This code is used to clean the waste data for 2021_22.
"""

#read the dataset
Wdata21_22 = pd.read_excel("/content/Waste Data 2021-22_Adj.xlsx", header=None)

#head
Wdata21_22.head()

#delete 20 rows downward
Wdata21_22 = Wdata21_22.drop(Wdata21_22.index[20:])

# forming new headers based on our targeted variables

cleaned_rows = []
num_cols = Wdata21_22.shape[1]
block_size = 15  # Each month is 15 columns wide

# 2. Iterate through each month block
for start_col in range(0, num_cols, block_size):
    year = Wdata21_22.iloc[2, start_col]
    month = Wdata21_22.iloc[3, start_col]

    # --- Recy_NonRecy ROW PROCESSING ---
    # We take the Recy_NonRecy row for this block and 'forward-fill' the names
    # so 'Incineration' covers both Non-recyclables and Bulky Waste, and 'Recycling' covers Mixed Recycling to Flu Tubes.
    Recy_NonRecy_row = Wdata21_22.iloc[4, start_col:start_col+block_size].copy()

    # Clean the row: replace 'Address Name' with NaN and strip spaces
    Recy_NonRecy_row = Recy_NonRecy_row.apply(lambda x: np.nan if str(x).strip().lower() == 'address_name' else x)

    # Use pandas ffill to spread the Recy_NonRecy name to the right
    filled_Recy_NonRecy = Recy_NonRecy_row.ffill().tolist()

    # --- WasteType ROW PROCESSING ---
    # Row 6 (Index 5) contains the names
    WasteTypes = Wdata21_22.iloc[5, start_col:start_col+block_size].tolist()

    # 3. Iterate through data columns (1 to 13)
    for j in range(1, 14):
        col_idx = start_col + j
        if col_idx >= num_cols: break

        Recy_NonRecy = filled_Recy_NonRecy[j]
        WasteType = WasteTypes[j]

        # Skip if there's no Recy_NonRecy label even after filling (usually empty spacer columns)
        if pd.isna(Recy_NonRecy): continue

        # Spelling Correction
        if isinstance(Recy_NonRecy, str) and "Recycled" in Recy_NonRecy or "Recycling" in Recy_NonRecy:
            Recy_NonRecy = "Recycled"

        if isinstance(Recy_NonRecy, str) and "Anerobic Digestion" in Recy_NonRecy :
            Recy_NonRecy = "AD"

        # 4. Iterate through address_name rows (Row index 6 onwards)
        for row_idx in range(6, len(Wdata21_22)):
            address_name = Wdata21_22.iloc[row_idx, start_col]
            kg = Wdata21_22.iloc[row_idx, col_idx]

            # Skip if address_name is empty or a repeat header
            if pd.isna(address_name) or str(address_name).strip().lower() in ["address_name", "WasteType's name"]:
                continue

            # Numeric conversion for Kg
            try:
                if isinstance(kg, str):
                    kg = kg.replace(',', '').strip()
                kg_val = float(kg)
            except (ValueError, TypeError):
                kg_val = np.nan

            cleaned_rows.append({
                'Year': year, 'Month': month, 'Address Name': address_name,
                'Recy_NonRecy': Recy_NonRecy, 'WasteType': WasteType, 'Kg': kg_val
            })

# 5. Create final DataFrame and Final Cleanup
Wdata21_22_clean = pd.DataFrame(cleaned_rows)
Wdata21_22_clean['Year'] = Wdata21_22_clean['Year'].ffill()
Wdata21_22_clean['Month'] = Wdata21_22_clean['Month'].ffill()

# Remove records where no kg was recorded (NaN)
Wdata21_22_clean = Wdata21_22_clean.dropna(subset=['Kg'])

# 6. Save
Wdata21_22_clean.to_csv('Waste_2021_2022_clean.csv', index=False)

#total Kg column
Wdata21_22_clean['Kg'].sum()

#head
Wdata21_22_clean.head()

# print total Kg for each Month from August to July
for month in Wdata21_22_clean['Month'].unique():
    total_kg = Wdata21_22_clean[Wdata21_22_clean['Month'] == month]['Kg'].sum()
    print(f"Total Kg for {month}: {total_kg}")

#bar chart for Kg and Treatment Mothod (Recy_NonRecy) 2021_2022
Wdata21_22_clean.groupby('Recy_NonRecy')['Kg'].sum().plot(kind='bar')

#plot bar chart for the WasteType and Kg
Wdata21_22_clean.groupby('WasteType')['Kg'].sum().plot(kind='bar')

#plot bar chart for the Address Name and Kg
Wdata21_22_clean.groupby('Address Name')['Kg'].sum().plot(kind='bar')

#unique Recy_NonRecy (list of treatment method 2021_22)
Wdata21_22_clean['Recy_NonRecy'].unique()



"""**2022_2023 Dataset**

The *tageted variables* for this third format would be "WasteType", Contractor, "Recy_NonRecy","Year", "Month", "Kg", "Total" and "Carbon Footprint".


Below is the **Waste Data Cleaning Step by Step for the third format** This code is used to clean the waste data from 2022_23 to 2024_25.
The first step is to import and install all the neccessary libraries that will help to read, transform and visualise the dataset. Then, upload all the yearly dataset into Colab.
"""

# load the dataset
Wdata22_23 = pd.read_excel('/content/Waste Data 2022-23_Adj.xlsx')

#print sample
Wdata22_23.head()

# check the shape
Wdata22_23.shape

#check basic info
Wdata22_23.info()

#describe
Wdata22_23.describe()

#describe with object
Wdata22_23.describe(include='object')

#Start the cleaning process
#Extract month names from row 2
months = Wdata22_23.iloc[0, 2:14].tolist() # row 2 and column of the months
print("Months:", months)     # ".iloc" allow access to rows and columns by their integer positions.

# looking for row where the data actually started
# Find first data in row
start_row = None
for i in range(len(Wdata22_23)):
    val = Wdata22_23.iloc[i, 0]
    if pd.notna(val) and isinstance(val, str) and ('Dr.' in val or '(' in val):
        start_row = i
        break

print("Data starts at row:", start_row)

# forming new dataset columns and rows
Wdata22_23_clean = Wdata22_23.iloc[start_row:, :19]  # 1st col + 12 months + Total
Wdata22_23_clean.columns = ['WasteType Contractor'] + ['Recy_NonRecy'] + months + ['Total1'] + ['Total'] + ['Monthly Average'] + ['Total Carbon'] +['Carbon Footprint']

# then reset index
Wdata22_23_clean = Wdata22_23_clean.reset_index(drop=True)

print(Wdata22_23_clean.info())

print(Wdata22_23_clean.head())

print(Wdata22_23_clean.tail())

# remove unnecessary summary label (like "Total Recycled", "Total incineration ", etc.)
Wdata22_23_clean = Wdata22_23_clean[~Wdata22_23_clean['WasteType Contractor'].str.contains('Total|Carbon|%|Monthly average', na=False)]

# Drop the empty columns
Wdata22_23_clean = Wdata22_23_clean.drop(columns=['Total Carbon', 'Total1'])

# Remove rows where WasteType Contractor is NaN or empty
Wdata22_23_clean = Wdata22_23_clean.dropna(subset=['WasteType Contractor'])

# Remove rows where Recy_NonRecy is NaN or empty
Wdata22_23_clean = Wdata22_23_clean.dropna(subset=['Recy_NonRecy'])

print(Wdata22_23_clean.head())

# split WasteType Contractor column into WasteType and Contractor
def split_WasteType_Contractor(text):
    text = str(text).strip()
    if '(' in text and ')' in text:
        WasteType = text.split('(')[0].strip()
        Contractor = text.split('(')[1].replace(')', '').strip()
        return pd.Series([WasteType, Contractor])
    else:
        # Handle cases with no contractor info
        return pd.Series([text, "Unknown"])

Wdata22_23_clean[['WasteType', 'Contractor']] = Wdata22_23_clean['WasteType Contractor'].apply(split_WasteType_Contractor)

#check for missing value
Wdata22_23_clean.isnull().sum()

# missing value percentage
missing_percentage = (Wdata22_23_clean.isnull().sum() / len(Wdata22_23_clean)) * 100
print(missing_percentage)

#check info
Wdata22_23_clean.info()



# Convert month column to numeric (handle commas if any)
for col in months:
    Wdata22_23_clean[col] = pd.to_numeric(Wdata22_23_clean[col], errors='coerce').fillna(0)

# Replace blank space in Total, Monthly_Avg, Points with zero
Wdata22_23_clean['Total'] = pd.to_numeric(Wdata22_23_clean['Total'], errors='coerce').fillna(0)
Wdata22_23_clean['Monthly Average'] = pd.to_numeric(Wdata22_23_clean['Monthly Average'], errors='coerce').fillna(0)
Wdata22_23_clean['Carbon Footprint'] = pd.to_numeric(Wdata22_23_clean['Carbon Footprint'], errors='coerce').fillna(0)

# Check the data types
print("\nData types:")
print(Wdata22_23_clean.dtypes)

#print sample , this is the large format
Wdata22_23_clean.head()

# Create Long-Format DataFrame (for easy analysis) by melting down the months
Wdata22_23_clean_long = Wdata22_23_clean.melt(
    id_vars=['WasteType', 'Contractor', 'Recy_NonRecy', 'Total', 'Carbon Footprint'],
    value_vars=months,
    var_name='Month',
    value_name='Kg'
)

# Add Year based on Month (Aug–Dec → 2022; Jan–July → 2023)
def fiscal_year(month):
    return 2022 if month in ['August','September','October', 'November', 'December'] else 2023

Wdata22_23_clean_long['Year'] = Wdata22_23_clean_long['Month'].apply(fiscal_year)

# Reorder for clarity
Wdata22_23_clean_long = Wdata22_23_clean_long[['WasteType', 'Contractor', 'Recy_NonRecy', 'Year', 'Month', 'Kg', 'Total', 'Carbon Footprint']]

# Remove rows with missing Kg
Wdata22_23_clean_long = Wdata22_23_clean_long[Wdata22_23_clean_long['Kg'] >= 0]

print("\nLong-format sample:")
print("\n", Wdata22_23_clean_long)

#drop column where Total is 0.0
Wdata22_23_clean_long = Wdata22_23_clean_long[Wdata22_23_clean_long['Total'] != 0.0]

#check info
Wdata22_23_clean_long.info()

#check missing value
Wdata22_23_clean_long.isnull().sum()

print(Wdata22_23_clean_long.head(5))

print(Wdata22_23_clean_long.tail(5))

#save to csv
Wdata22_23_clean_long.to_csv('Wdata22_23_clean_long.csv', index=False)

#read Wdata22_23_clean_long.csv
Wdata22_23_clean_long = pd.read_csv("/content/Wdata22_23_clean_long.csv")

#check Kg total
Wdata22_23_clean_long['Kg'].sum()

#plot Wdata22_23_clean_long bar chart of Kg and Recy_NonRecy with label x-axis= "Tratment Method", y-axis = " Quantities in Kg" and Title = " Waste Treatment Methods and Quantities 2022-2023"
plt.figure(figsize=(10, 6))
Wdata22_23_clean_long.groupby('Recy_NonRecy')['Kg'].sum().plot(kind='bar')
plt.xlabel('Treatment Method')
plt.ylabel('Quantities in Kg')
plt.title('Waste Treatment Methods and Quantities 2022-2023')
plt.show()



# #plot Wdata22_23_clean_long bar chart of WasteType and Kg and with label x-axis= "Waste Type", y-axis = " Quantities in Kg" and Title =" Distribution of Waste Type Collected at UoW in 2022-2023 (Kg)"
plt.figure(figsize=(10, 6))
Wdata22_23_clean_long.groupby('WasteType')['Kg'].sum().plot(kind='bar')
plt.xlabel('Waste Type')
plt.ylabel('Quantities in Kg')
plt.title('Distribution of Waste Type Collected at UoW in 2022-2023 (Kg)')
plt.show()

#plot Wdata22_23_clean_long pie chart of Kg and Recy_NonRecy
plt.figure(figsize=(10, 6))
Wdata22_23_clean_long.groupby('Recy_NonRecy')['Kg'].sum().plot(kind='pie', autopct='%1.1f%%')

#plot boxplot for WasteType and Kg with label x-axis= "Waste Type", y-axis = " Quantities in Kg" and Title = " Distribution of Waste Quantities by Waste Type 2022-2023"
plt.figure(figsize=(10, 6))
sns.boxplot(x='WasteType', y='Kg', data=Wdata22_23_clean_long)
plt.xlabel('Waste Type')
plt.ylabel('Quantities in Kg')
plt.title('Distribution of Waste Quantities by Waste Type 2022-2023')
plt.show()



#plot boxplot for Recy_NonRecy
plt.figure(figsize=(10, 6))
sns.boxplot(x='Recy_NonRecy', y='Kg', data=Wdata22_23_clean_long)
plt.show()



#plot pie for Carbon Footprint,  WasteType
plt.figure(figsize=(10, 6))
Wdata22_23_clean_long.groupby('WasteType')['Carbon Footprint'].sum().plot(kind='pie', autopct='%1.1f%%')



#plot bar for Carbon Footprint and WasteType
plt.figure(figsize=(10, 6))
sns.barplot(x='WasteType', y='Carbon Footprint', data=Wdata22_23_clean_long)
plt.show()



# plot bar chart for Carbon Footprint and Recy_NonRecy
plt.figure(figsize=(10, 6))
sns.barplot(x='Recy_NonRecy', y='Carbon Footprint', data=Wdata22_23_clean_long)
plt.show()

# plot bar chart for Contractor and Kg
plt.figure(figsize=(10, 6))
sns.barplot(x='Contractor', y='Kg', data=Wdata22_23_clean_long)
plt.xticks(rotation=90)
plt.show()

#drop "WasteType Contractor" column
Wdata22_23_clean = Wdata22_23_clean.drop(columns=['WasteType Contractor'])

"""**Transfer** all the cleaned saved csv datasets into sqlite storage"""

# connect to database
conn = sqlite3.connect("Wastedb")
cur = conn.cursor()

# I used this code to move my new sqlite database into my google drive for easy access
#import shutil
#shutil.move('Wastedb', '/content/drive/MyDrive/School/xxxxxxx/xxxxxxx/FYPdb/Wastedb')



# Read the cleaned 2017_2018 csv waste dataset
Wdata2017_2018_clean = pd.read_csv("/content/Waste_2017_2018_Clean.csv")

# transfer the clean Wdata2017_2018 csv to "W17_18" table in the sqlite for storage
Wdata2017_2018_clean.to_sql(
    "W17_18",
    conn,
    if_exists="replace",
    index=False
)

#check the content of table "W17_18"
W17_18 = pd.read_sql('SELECT * FROM W17_18 LIMIT 10', conn)
W17_18

# sum total of Kg in table W17_18
query = "SELECT SUM(Kg) FROM W17_18"
result = pd.read_sql(query, conn)
print(result)



"""waste data 2018_19 to sql"""

#read 2018_19 csv waste data
Wdata18_19_clean = pd.read_csv("/content/Waste_2018_2019_Clean.csv")

# load dataframes into database As table with names W18_19
Wdata18_19_clean.to_sql("W18_19",   conn,
    if_exists="replace",
    index=False)

# CHECK DATA INSERTED INTO TABLE W18_19
W18_19 = pd.read_sql('SELECT * FROM W18_19 LIMIT 10', conn)
W18_19

# CHECK DATA INSERTED INTO TABLE W18_19 DESC
query = "SELECT * FROM W18_19 ORDER BY Year DESC"
result = pd.read_sql(query, conn)
print(result)



# sum total of Kg in table W18_19
query = "SELECT SUM(Kg) FROM W18_19"
result = pd.read_sql(query, conn)
print(result)



"""Waste data 2019_20 to sql"""

#read 2019_20 csv waste data
Wdata19_20_clean = pd.read_csv("/content/Waste_2019_2020_Clean.csv")

# load dataframes into database As table with names W19_20
Wdata19_20_clean.to_sql("W19_20",   conn,
    if_exists="replace",
    index=False)

# CHECK DATA INSERTED INTO TABLE W19_20
W19_20 = pd.read_sql('SELECT * FROM W19_20 LIMIT 10', conn)
W19_20

# sum total of Kg in table W19_20
query = "SELECT SUM(Kg) FROM W19_20"
result = pd.read_sql(query, conn)
print(result)



"""**Waste data 2020_21 to sql**"""

#read 2020_2021_Clean csv waste data
clean_Wdata20_21 = pd.read_csv("/content/Waste_2020_2021_Clean.csv")

# load dataframes into database As table with names W20_21
clean_Wdata20_21.to_sql("W20_21", conn,
    if_exists="replace",
    index=False)

# CHECK IF DATA INSERTED INTO TABLES W20_21
W20_21 = pd.read_sql('SELECT * FROM W20_21 LIMIT 10', conn)
W20_21

# CHECK DATA INSERTED INTO TABLE W20_21 DESC
query = "SELECT * FROM W20_21 ORDER BY Year DESC"
result = pd.read_sql(query, conn)
print(result)

# 3. running a SQL query for only 2021
query = "SELECT Recy_NonRecy, SUM(Kg) FROM W20_21 WHERE Year != '2020' GROUP BY Recy_NonRecy"
result = pd.read_sql(query, conn)
print(result)

# sum total of Kg in table W20_21
query = "SELECT SUM(Kg) FROM W20_21"
result = pd.read_sql(query, conn)
print(result)



"""**waste data 2021_22 to sql**"""

#read 2021_22_Clean csv waste data
clean_Wdata2021_22 = pd.read_csv("/content/Waste_2021_2022_clean.csv")

# load dataframes into database As table with names W21_22
clean_Wdata2021_22.to_sql("W21_22", conn,
    if_exists="replace",
    index=False)

# CHECK IF DATA INSERTED INTO TABLES W21_22
W21_22 = pd.read_sql('SELECT * FROM W21_22 LIMIT 10', conn)
W21_22

# 3. running a SQL query for only 2022
query = "SELECT Recy_NonRecy, SUM(Kg) FROM W21_22 WHERE Year != '2021' GROUP BY Recy_NonRecy"
result = pd.read_sql(query, conn)
print(result)

# sum total of Kg in table W21_22
query = "SELECT SUM(Kg) FROM W21_22"
result = pd.read_sql(query, conn)
print(result)



"""waste data 2022_23 to sql"""

#read 2022_23_Clean csv waste data
clean_WdataW22_23 = pd.read_csv("/content/Wdata22_23_clean_long.csv")

# load dataframes into database As table with names W22_23
clean_WdataW22_23.to_sql("W22_23", conn,
    if_exists="replace",
    index=False)



# CHECK IF DATA INSERTED INTO TABLES W22_23
W22_23 = pd.read_sql('SELECT * FROM W22_23 LIMIT 10', conn)
W22_23

# sum total of Kg in table W22_23
query = "SELECT SUM(Kg) FROM W22_23"
result = pd.read_sql(query, conn)
print(result)



"""waste data 2023_24 to sql"""

#read 2023_24_Clean csv waste data
clean_WdataW23_24 = pd.read_csv("/content/Wdata2023_24_clean_long.csv")

# load dataframes into database As table with names W23_24
clean_WdataW23_24.to_sql("W23_24", conn,
    if_exists="replace",
    index=False)

# CHECK IF DATA INSERTED INTO TABLES "W23_24"
W23_24 = pd.read_sql('SELECT * FROM W23_24 LIMIT 10', conn)
W23_24

# sum total of Kg in table WW23_24
query = "SELECT SUM(Kg) FROM W23_24"
result = pd.read_sql(query, conn)
print(result)



"""waste data 2024_25 to sql"""

# Read the cleaned 2024_2025 csv waste dataset
Wdata2024_25_clean_long = pd.read_csv("/content/Wdata2024_25_clean_long.csv")

#Check the sample of the loaded clean dataset
Wdata2024_25_clean_long.tail()

# transfer the clean Wdata2024_25 csv to "W24_25" table in the sqlite for storage
Wdata2024_25_clean_long.to_sql(
    "W24_25",
    conn,
    if_exists="replace",
    index=False
)

#check the content of table "W24_25"
W24_25 = pd.read_sql('SELECT * FROM W24_25 LIMIT 160', conn)
W24_25

# sum total of Kg in table W24_25
query = "SELECT SUM(Kg) FROM W24_25"
result = pd.read_sql(query, conn)
print(result)



"""Note "cursor" to run form here is defined in the first cell ("auto load the database") which is put in the report, just copy from the report and paste, it would run"""

# Check /print the columns for every table to help in comparing the tables. Note "cursor" to run form here is defined in the first cell (auto load the database) which is put in the report, just copy and paste, it would run
for table in ['W17_18', 'W18_19', 'W19_20', 'W20_21', 'W21_22', 'W22_23', 'W23_24', 'W24_25']:
    cursor.execute(f"PRAGMA table_info({table})")
    columns = [col[1] for col in cursor.fetchall()]
    print(f"Table {table} has {len(columns)} columns: {columns}\n")

cursor.execute("""
SELECT `Address Name`, SUM(Kg) AS total_kgw17_18
FROM W17_18
GROUP BY `Address Name`
""")

rows = cursor.fetchall()

for address, total_kgw17_18 in rows:
    print(address, total_kgw17_18)

#print total kg for 2017_18 from the database
cursor.execute("""
SELECT SUM(Kg) AS total_kgw17_18
FROM W17_18
""")

result = cursor.fetchone()
print(result[0])



"""**Designing the Schema**      

The PostgreSQL "Star Schema" Design.

Instead of 8 different tables for each academic section, I will create a **Central Fact Table** for the 4 columns that are common in every dataset, and a **Details Table** for the information that are not commom to each table.

1. The Fact Table (waste_summary)
This table holds the core column that are common across all 8 tables.

Columns: **record_id (Primary Key)**, Year, Month, Recy_NonRecy, and Kg.

2. The Details Table (waste_details)
This table holds the columns that only appear in *certain table or Waste/years* (like Address Name or Carbon Footprint). We *link* it to the Fact table using a record_id.

Columns: **record_id (Foreign Key)**, Address_Name, WasteType, Contractor, Total, Carbon_Footprint.

First we need to Set up Postgres server in Colab environment
"""

# Install the Postgres server
!apt install postgresql postgresql-contrib &> /dev/null
!service postgresql start

# Create a user (wastemgt_team) and database
!sudo -u postgres psql -c "CREATE USER wastemgt_team WITH PASSWORD 'xxxxxxxx';"
!sudo -u postgres psql -c "CREATE DATABASE waste_db2;"
!sudo -u postgres psql -c "GRANT ALL PRIVILEGES ON DATABASE waste_db2 TO wastemgt_team;"

# Install the Python connector
import psycopg2
conn = psycopg2.connect(database="xxxxxxxx", user="wastemgt_team", password="xxxxxxxx", host="127.0.0.1", port="5432")
cursor = conn.cursor()
print("PostgreSQL server is ready!")



# connect to our database in sqlite
import sqlite3
import psycopg2
import os

pg_conn = psycopg2.connect(database="xxxxxxxx", user="wastemgt_team", password="xxxxxxxx", host="127.0.0.1", port="5432")
pg_cursor = pg_conn.cursor()
sqlite_conn = sqlite3.connect('//content/drive/MyDrive/School/Third Year/Project/FYPdb/xxxxxx')
print(" Connections established.")

"""PostgreSQL database is empty. I will now create 2 tables one Central Fact Table for the 4 columns that are common in every dataset, and a Details Table for the information that are not commnon to each year."""

# Creating table in the PostgreSQL

pg_cursor.execute("DROP TABLE IF EXISTS waste_details CASCADE;")
pg_cursor.execute("DROP TABLE IF EXISTS waste_summary CASCADE;")

pg_cursor.execute("""
CREATE TABLE waste_summary (
    record_id SERIAL PRIMARY KEY,
    year INTEGER,
    month TEXT,
    recy_nonrecy TEXT,
    kg NUMERIC
);
""")
pg_cursor.execute("""
CREATE TABLE waste_details (
    detail_id SERIAL PRIMARY KEY,
    record_id INTEGER REFERENCES waste_summary(record_id),
    address_name TEXT,
    waste_type TEXT,
    contractor TEXT,
    total NUMERIC,
    carbon_footprint NUMERIC
);
""")
pg_conn.commit()



# migrating table from Sqlite to the new tables created
#  MIGRATION LOOP
tables = ['W17_18', 'W18_19', 'W19_20', 'W20_21', 'W21_22', 'W22_23', 'W23_24', 'W24_25']

for table_name in tables:
    df = pd.read_sql(f"SELECT * FROM {table_name}", sqlite_conn)
    for _, row in df.iterrows():
        # Insert into Summary
        pg_cursor.execute("""
            INSERT INTO waste_summary (year, month, recy_nonrecy, kg)
            VALUES (%s, %s, %s, %s) RETURNING record_id;
        """, (row['Year'], row['Month'], row['Recy_NonRecy'], row['Kg']))

        new_id = pg_cursor.fetchone()[0]

        # Insert into Details (Handling the columns that vary by year)
        pg_cursor.execute("""
            INSERT INTO waste_details (record_id, address_name, waste_type, contractor, total, carbon_footprint)
            VALUES (%s, %s, %s, %s, %s, %s);
        """, (new_id, row.get('Address Name'), row.get('WasteType'), row.get('Contractor'), row.get('Total'), row.get('Carbon Footprint')))

    print(f" Migrated {table_name}")

pg_conn.commit()
print("\n  All data moved to PostgreSQL!")

#checking if the tables created are working:
# Check the count of rows in the new PostgreSQL table
pg_cursor.execute("SELECT COUNT(*) FROM waste_summary;")
count = pg_cursor.fetchone()[0]
print(f"PostgreSQL now contains {count} records!")

"""Create a Master View in PostgreSQL that combine/ integrating two tables together for easy query"""

# Create the Master View joining both tables
pg_cursor.execute("""
CREATE OR REPLACE VIEW master_waste_view AS
SELECT
    s.record_id,
    s.year,
    TRIM(s.month) as month, -- This removes the trailing space from 'July '
    s.recy_nonrecy,
    s.kg,
    d.address_name,
    d.waste_type,
    d.contractor,
    d.total,
    d.carbon_footprint
FROM waste_summary s
JOIN waste_details d ON s.record_id = d.record_id;
""")
pg_conn.commit()

print(" Master View 'master_waste_view' created!")

# Query the Master View to check if it is created
query = "SELECT * FROM master_waste_view WHERE year = 2020 LIMIT 5;"
check_view = pd.read_sql(query, pg_conn)

# This will show the Year, Kg, AND the Carbon Footprint all in one row
check_view.head()

""""I have upgraded the data from CSV structure to a Relational PostgreSQL Schema. I used a normalized design with a central waste_summary table and a waste_details extension. To ensure ease of use, I created a Master View that automatically joins these tables, providing a unified interface for all 8 years of data while maintaining data integrity."
"""



"""Creating SQLAlchemy Engine as a permanent "connection manager."
"""

from sqlalchemy import create_engine
import pandas as pd

# 1. Create the SQLAlchemy Engine
# Format: postgresql+psycopg2://username:password@host:port/database_name
engine = create_engine('postgresql+psycopg2://wastemgt_team:xxxxxxxxx@127.0.0.1:5432/xxxxxxx')



# Query to calculate totals based on the Academic Session (Aug to July) from the master_waste_view created
academic_query = """
SELECT
    CASE
        WHEN (year = 2017 AND month IN ('August', 'September', 'October', 'November', 'December'))
             OR (year = 2018 AND month IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
             THEN 'W17_18'
        WHEN (year = 2018 AND month IN ('August', 'September', 'October', 'November', 'December'))
             OR (year = 2019 AND month IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
             THEN 'W18_19'
        WHEN (year = 2019 AND month IN ('August', 'September', 'October', 'November', 'December'))
             OR (year = 2020 AND month IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
             THEN 'W19_20'
        WHEN (year = 2020 AND month IN ('August', 'September', 'October', 'November', 'December'))
             OR (year = 2021 AND month IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
             THEN 'W20_21'
        WHEN (year = 2021 AND month IN ('August', 'September', 'October', 'November', 'December'))
             OR (year = 2022 AND month IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
             THEN 'W21_22'
        WHEN (year = 2022 AND month IN ('August', 'September', 'October', 'November', 'December'))
             OR (year = 2023 AND month IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
             THEN 'W22_23'
        WHEN (year = 2023 AND month IN ('August', 'September', 'October', 'November', 'December'))
             OR (year = 2024 AND month IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
             THEN 'W23_24'
        WHEN (year = 2024 AND month IN ('August', 'September', 'October', 'November', 'December'))
             OR (year = 2025 AND month IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
             THEN 'W24_25'
        ELSE 'Other'
    END AS academic_session,
    ROUND(SUM(kg), 2) as total_kg,
    COUNT(*) as record_count
FROM master_waste_view
GROUP BY academic_session
ORDER BY academic_session ASC;
"""

df_academic_annual = pd.read_sql(academic_query, engine)


print(" Waste Totals by Academic Session (August to July):")
print(df_academic_annual[df_academic_annual['academic_session'] != 'Other'])

#"Year-over-Year" Growth Query
yoy_query = """
WITH session_totals AS (
    -- First, we get the totals using the flexible logic
    SELECT
        CASE
            WHEN (year = 2017 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2018 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W17_18'
            WHEN (year = 2018 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2019 AND TRIM(month) IN ('January',  'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W18_19'
            WHEN (year = 2019 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2020 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W19_20'
            WHEN (year = 2020 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2021 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W20_21'
            WHEN (year = 2021 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2022 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W21_22'
            WHEN (year = 2022 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2023 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W22_23'
            WHEN (year = 2023 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2024 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W23_24'
            WHEN (year = 2024 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2025 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W24_25'
        END AS academic_session,
        SUM(kg) as current_kg
    FROM master_waste_view
    GROUP BY academic_session
)
SELECT
    academic_session,
    ROUND(current_kg, 2) as kg_this_session,
    ROUND(LAG(current_kg) OVER (ORDER BY academic_session), 2) as kg_prev_session,
    ROUND(current_kg - LAG(current_kg) OVER (ORDER BY academic_session), 2) as net_change,
    ROUND(((current_kg - LAG(current_kg) OVER (ORDER BY academic_session)) /
           NULLIF(LAG(current_kg) OVER (ORDER BY academic_session), 0)) * 100, 2) as percentage_growth
FROM session_totals
WHERE academic_session IS NOT NULL
ORDER BY academic_session;
"""

df_yoy = pd.read_sql(yoy_query, engine)
print("Comparative Waste Growth Analysis:")
print(df_yoy)

"""**A Waterfall Chart**
I have set the colors so that Green represents a decrease while Red represents the increase in the waste
"""

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# 1. Fetch the data using the engine
query = """
WITH session_totals AS (
    SELECT
        CASE
            WHEN (year = 2017 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2018 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W17_18'
            WHEN (year = 2018 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2019 AND TRIM(month) IN ('January',  'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W18_19'
            WHEN (year = 2019 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2020 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W19_20'
            WHEN (year = 2020 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2021 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W20_21'
            WHEN (year = 2021 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2022 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W21_22'
            WHEN (year = 2022 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2023 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W22_23'
            WHEN (year = 2023 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2024 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W23_24'
            WHEN (year = 2024 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2025 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W24_25'
        END AS academic_session,
        SUM(kg) as total_kg
    FROM master_waste_view
    GROUP BY academic_session
    ORDER BY academic_session
)
SELECT * FROM session_totals WHERE academic_session IS NOT NULL;
"""

df = pd.read_sql(query, engine)

# 2. Prepare Waterfall Logic
df['delta'] = df['total_kg'].diff().fillna(0)
index = df['academic_session']
data = df['total_kg']
changes = df['delta']

# 3. Plotting
plt.figure(figsize=(14, 7))

# Initial baseline bar
plt.bar(index[0], data[0], color='#2c3e50', label='Baseline (17/18)')

# Running total for the 'bottom' of each change bar
current_total = data[0]

for i in range(1, len(index)):
    # Color: Green for waste reduction (negative change), Red for increase (positive)
    # Note: In waste management, a decrease is "Good" (Green)
    color = '#27ae60' if changes[i] < 0 else '#e74c3c'

    # We plot the change bar
    plt.bar(index[i], changes[i], bottom=current_total, color=color)

    # Draw a small connector line
    plt.plot([i-1, i], [current_total, current_total], color='gray', linestyle='--', alpha=0.3)

    current_total += changes[i]

# Final Total Bar
plt.bar('Current', current_total, color='#34495e', label='Final Status')

# Formatting
plt.title('Waste Output Change: Academic Session Waterfall (2017 - 2025)', fontsize=16)
plt.ylabel('Waste Volume (Kg)', fontsize=12)
plt.xlabel('Academic Session', fontsize=12)
plt.grid(axis='y', alpha=0.3)
plt.legend(['Connection', 'Baseline', 'Decrease (Good)', 'Increase (Bad)', 'Final'], loc='upper left')

plt.show()



# This query extracts every unique waste category in the master_waste_view
type_check_query = """
SELECT DISTINCT
    recy_nonrecy,
    waste_type
FROM master_waste_view
ORDER BY recy_nonrecy;
"""

df_types = pd.read_sql(type_check_query, engine)

print("Your Unique Waste Categories:")
print(df_types)



# Plotting monthly waste (Kg) in each Academic Session.
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

# We use a subquery (the SELECT inside the FROM) to define the session name first
heatmap_query = """
SELECT academic_session, month_name, SUM(kg) as total_kg
FROM (
    SELECT
        CASE
            WHEN (year = 2017 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2018 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W17_18'
            WHEN (year = 2018 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2019 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W18_19'
            WHEN (year = 2019 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2020 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W19_20'
            WHEN (year = 2020 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2021 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W20_21'
            WHEN (year = 2021 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2022 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W21_22'
            WHEN (year = 2022 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2023 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W22_23'
            WHEN (year = 2023 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2024 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W23_24'
            WHEN (year = 2024 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2025 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W24_25'
        END AS academic_session,
        TRIM(month) as month_name,
        kg
    FROM master_waste_view
) as subquery
WHERE academic_session IS NOT NULL
GROUP BY academic_session, month_name;
"""

df_heat = pd.read_sql(heatmap_query, engine)

# 2. Define the correct Academic Order
academic_months = ['August', 'September', 'October', 'November', 'December',
                   'January', 'February', 'March', 'April', 'May', 'June', 'July']

# 3. Pivot the data
pivot_df = df_heat.pivot(index='academic_session', columns='month_name', values='total_kg')

# 4. Reorder columns
pivot_df = pivot_df.reindex(columns=academic_months)

# 5. Plot the Heatmap
plt.figure(figsize=(14, 8))
sns.heatmap(pivot_df, annot=True, fmt=".0f", cmap="YlOrRd", linewidths=.5)

plt.title('Seasonal Waste Density: Academic Session vs. Month (Kg)', fontsize=16)
plt.ylabel('Academic Session', fontsize=12)
plt.xlabel('Month (Ordered August to July)', fontsize=12)

plt.show()

"""**The Waste Diversion Rate**
This shows percentage of the school's total waste was "diverted" from being burned or sent to a landfill through recycling, composting (AD), or reuse.

Diversion excluding incineration



 **Sustainability Insight**  A higher diversion rate directly impacts the Carbon Footprint. Every 1% increase in the diversion rate typically results in a significant drop in total $CO_{2}e$, because recycling a material uses far less energy than manufacturing it from scratch or burning it.

Waste Diversion Rate Trend (2017-2025)
"""

# Plot Waste Diversion Rate Trend (2017-2025)

import matplotlib.pyplot as plt
import pandas as pd

# 1. Query to calculate Diverted vs. Total waste per session
diversion_query = """
SELECT
    academic_session,
    SUM(CASE WHEN recy_nonrecy IN ('Recycled', 'AD', 'Re-use', 'Reuse') THEN kg ELSE 0 END) as diverted_kg,
    SUM(kg) as total_kg
FROM (
    SELECT
        CASE
            WHEN (year = 2017 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2018 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W17_18'
            WHEN (year = 2018 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2019 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W18_19'
            WHEN (year = 2019 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2020 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W19_20'
            WHEN (year = 2020 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2021 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W20_21'
            WHEN (year = 2021 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2022 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W21_22'
            WHEN (year = 2022 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2023 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W22_23'
            WHEN (year = 2023 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2024 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W23_24'
            WHEN (year = 2024 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2025 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W24_25'
        END AS academic_session,
        recy_nonrecy,
        kg
    FROM master_waste_view
) as subquery
WHERE academic_session IS NOT NULL
GROUP BY academic_session
ORDER BY academic_session;
"""

df_div = pd.read_sql(diversion_query, engine)

# 2. Calculate the rate
df_div['diversion_rate'] = (df_div['diverted_kg'] / df_div['total_kg']) * 100

# 3. Plotting
plt.figure(figsize=(12, 6))
plt.plot(df_div['academic_session'], df_div['diversion_rate'], marker='o', linestyle='-', color='#16a085', linewidth=3)

# Add data labels
for i, rate in enumerate(df_div['diversion_rate']):
    plt.text(i, rate + 1, f"{rate:.1f}%", ha='center', fontweight='bold')

plt.title('Waste Diversion Rate Trend (2017-2025)', fontsize=15)
plt.ylabel('Percentage of Waste Diverted (%)')
plt.xlabel('Academic Session')
plt.ylim(0, max(df_div['diversion_rate']) + 15) # Leave space for labels
plt.grid(axis='y', alpha=0.3)

plt.show()



"""**Diversion Bar Chart** : This compares the Total Waste against the Diverted Waste for every academic session from August 2017 to July 2025.

**Volume vs. Efficiency**: If the green bar is growing faster than the dark bar, the sustainability program is succeeding.
"""

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

# 1. SQL Query to get Total vs. Diverted Kg
bar_query = """
SELECT
    academic_session,
    ROUND(SUM(kg), 2) as total_kg,
    ROUND(SUM(CASE WHEN recy_nonrecy IN ('Recycled', 'AD', 'Re-use', 'Reuse') THEN kg ELSE 0 END), 2) as diverted_kg
FROM (
    SELECT
        CASE
            WHEN (year = 2017 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2018 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W17_18'
            WHEN (year = 2018 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2019 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W18_19'
            WHEN (year = 2019 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2020 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W19_20'
            WHEN (year = 2020 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2021 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W20_21'
            WHEN (year = 2021 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2022 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W21_22'
            WHEN (year = 2022 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2023 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W22_23'
            WHEN (year = 2023 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2024 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W23_24'
            WHEN (year = 2024 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2025 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W24_25'
        END AS academic_session,
        recy_nonrecy,
        kg
    FROM master_waste_view
) as subquery
WHERE academic_session IS NOT NULL
GROUP BY academic_session
ORDER BY academic_session;
"""

df_bar = pd.read_sql(bar_query, engine)

# 2. Setup the plot
x = np.arange(len(df_bar['academic_session']))  # Label locations
width = 0.35  # Width of the bars

fig, ax = plt.subplots(figsize=(14, 7))

# Plot Total vs Diverted
rects1 = ax.bar(x - width/2, df_bar['total_kg'], width, label='Total Waste (Kg)', color='#34495e')
rects2 = ax.bar(x + width/2, df_bar['diverted_kg'], width, label='Diverted (Recycled/AD/Reuse)', color='#27ae60')

# Add text for labels, title and custom x-axis tick labels, etc.
ax.set_ylabel('Weight (Kg)', fontsize=12)
ax.set_title('Total Waste vs. Diverted Volume by Academic Session', fontsize=16, fontweight='bold')
ax.set_xticks(x)
ax.set_xticklabels(df_bar['academic_session'])
ax.legend()

# Add value labels on top of bars
def autolabel(rects):
    for rect in rects:
        height = rect.get_height()
        ax.annotate(f'{height:,.0f}',
                    xy=(rect.get_x() + rect.get_width() / 2, height),
                    xytext=(0, 3),  # 3 points vertical offset
                    textcoords="offset points",
                    ha='center', va='bottom', fontsize=9)

autolabel(rects1)
autolabel(rects2)

plt.grid(axis='y', linestyle='--', alpha=0.3)
plt.tight_layout()
plt.show()



# Plot Leaderboard showing Diversion Rate by Campuses/ Locations
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns

# 1. SQL Query - Added a filter to remove NULL addresses
location_query = """
SELECT
    address_name,
    SUM(kg) as total_kg,
    SUM(CASE WHEN recy_nonrecy IN ('Recycled', 'AD', 'Re-use', 'Reuse') THEN kg ELSE 0 END) as diverted_kg
FROM master_waste_view
WHERE address_name IS NOT NULL  -- This prevents the TypeError
GROUP BY address_name
HAVING SUM(kg) > 0
"""

df_loc = pd.read_sql(location_query, engine)

# 2. Calculate Diversion Rate %
df_loc['diversion_rate'] = (df_loc['diverted_kg'] / df_loc['total_kg']) * 100

# 3. Sort by Diversion Rate
df_loc = df_loc.sort_values(by='diversion_rate', ascending=True)

# 4. Plotting
plt.figure(figsize=(12, 10))

# Create the color list based on the cleaned dataframe
colors = ['#27ae60' if x >= 50 else '#e67e22' for x in df_loc['diversion_rate']]

bars = plt.barh(df_loc['address_name'], df_loc['diversion_rate'], color=colors)

# Add percentage labels
for bar in bars:
    width = bar.get_width()
    plt.text(width + 1, bar.get_y() + bar.get_height()/2,
             f'{width:.1f}%', va='center', fontweight='bold')

plt.title('Campus Sustainability Leaderboard: Diversion Rate by Campuses', fontsize=16)
plt.xlabel('Diversion Rate (%)')
plt.ylabel('Campus / Location Name')
plt.xlim(0, 105) # Increased to 105 to leave room for text labels
plt.grid(axis='x', linestyle='--', alpha=0.4)

# Add target line
plt.axvline(x=50, color='#c0392b', linestyle='--', label='School Sustainability Target (50%)')
plt.legend(loc='lower right')

plt.tight_layout()
plt.show()



# Plot Waste Recycled Rate Trend (2017-2025)

import matplotlib.pyplot as plt
import pandas as pd

# 1. Query to calculate Recycled vs. Total waste per session
recycled_query = """
SELECT
    academic_session,
    SUM(CASE WHEN recy_nonrecy IN ('Recycled') THEN kg ELSE 0 END) as recycled_kg,
    SUM(kg) as total_kg
FROM (
    SELECT
        CASE
            WHEN (year = 2017 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2018 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W17_18'
            WHEN (year = 2018 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2019 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W18_19'
            WHEN (year = 2019 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2020 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W19_20'
            WHEN (year = 2020 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2021 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W20_21'
            WHEN (year = 2021 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2022 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W21_22'
            WHEN (year = 2022 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2023 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W22_23'
            WHEN (year = 2023 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2024 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W23_24'
            WHEN (year = 2024 AND TRIM(month) IN ('August', 'September', 'October', 'November', 'December'))
                 OR (year = 2025 AND TRIM(month) IN ('January', 'February', 'March', 'April', 'May', 'June', 'July'))
                 THEN 'W24_25'
        END AS academic_session,
        recy_nonrecy,
        kg
    FROM master_waste_view
) as subquery
WHERE academic_session IS NOT NULL
GROUP BY academic_session
ORDER BY academic_session;
"""

df_div = pd.read_sql(recycled_query, engine)

# 2. Calculate the rate
df_div['recycled_rate'] = (df_div['recycled_kg'] / df_div['total_kg']) * 100

# 3. Plotting
plt.figure(figsize=(12, 6))
plt.plot(df_div['academic_session'], df_div['recycled_rate'], marker='o', linestyle='-', color='#16a085', linewidth=3)

# Add data labels
for i, rate in enumerate(df_div['recycled_rate']):
    plt.text(i, rate + 1, f"{rate:.1f}%", ha='center', fontweight='bold')

plt.title('Waste Recycled Rate Trend (2017-2025)', fontsize=15)
plt.ylabel('Percentage of Waste Recycled (%)')
plt.xlabel('Academic Session')
plt.ylim(0, max(df_div['recycled_rate']) + 15) # Leave space for labels
plt.grid(axis='y', alpha=0.3)

plt.show()